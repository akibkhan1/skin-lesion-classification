{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implementing_Pix2Pix_PyTorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPvnvC0IWRTBedmUq2uwHqp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akibkhan1/skin-lesion-classification/blob/main/Implementing_Pix2Pix_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGNyiiiw3j5R"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsa-PSuI33x_"
      },
      "source": [
        "### Building Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKkkKnRb32zT"
      },
      "source": [
        "class disc_block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride=2):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=stride, bias=False, padding_mode=\"reflect\"),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "class discriminator(nn.Module):\n",
        "  def __init__(self, in_channels=3, channels=[64, 128, 256, 512]):  # takes 256*256*3 input image down to 33*33*512\n",
        "    super().__init__()\n",
        "\n",
        "    # the initial block is different from the general sequential blocks. it doesn't contain BatchNorm\n",
        "\n",
        "    self.initial_block = nn.Sequential(\n",
        "        nn.Conv2d(in_channels*2, channels[0], kernel_size=4, stride=2, padding=1, padding_mode=\"reflect\"),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "    # creating the subsequent blocks after the initial block\n",
        "\n",
        "    blocks = []\n",
        "    in_channels = channels[0]\n",
        "\n",
        "    for channel in channels[1:]:\n",
        "      blocks.append(\n",
        "          disc_block(in_channels, channel, stride=1 if channel == channels[-1] else 2)  # in the last 512 convolution, authors used a stride of 1\n",
        "      )\n",
        "      in_channels = channel\n",
        "\n",
        "    blocks.append(\n",
        "        nn.Conv2d(in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\")\n",
        "    )\n",
        "\n",
        "    self.model = nn.Sequential(*blocks)\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    x = torch.cat([x, y], dim=1)\n",
        "    x = self.initial_block(x)\n",
        "    return self.model(x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRdkxy0vBFtC"
      },
      "source": [
        "### Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okb1iqO_BLfz"
      },
      "source": [
        "def test():\n",
        "  x = torch.rand((1, 3, 256, 256))\n",
        "  y = torch.rand((1, 3, 256, 256))\n",
        "  model = discriminator()\n",
        "  preds = model(x, y)\n",
        "  print(preds.shape)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XszZU5HsCCsQ",
        "outputId": "7f43c619-a677-41ca-d8a6-9ebbcd01757a"
      },
      "source": [
        "test()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 26, 26])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFwPpn9ur3IO"
      },
      "source": [
        "### Building Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4DEZ77Pr0_s"
      },
      "source": [
        "class gen_block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, contracting_path=True, activation=\"relu\", use_dropout=False):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "      nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False, padding_mode='reflect') if contracting_path\n",
        "      else nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.ReLU() if activation == \"relu\"\n",
        "      else nn.LeakyReLU(0.2)\n",
        "    )\n",
        "    self.use_dropout = use_dropout\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return self.dropout(x) if self.use_dropout else x\n",
        "\n",
        "class generator(nn.Module):\n",
        "  def __init__(self, in_channels=3, channels=64):\n",
        "    super().__init__()\n",
        "\n",
        "    # the initial block is different from the general sequential blocks. it doesn't contain BatchNorm\n",
        "\n",
        "    self.initial_block = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, channels, kernel_size=4, stride=2, padding=1, padding_mode=\"reflect\"),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    ) # 128\n",
        "\n",
        "    # creating the subsequent blocks after the initial block\n",
        "\n",
        "    self.down1 = gen_block(channels, channels*2, contracting_path=True, activation=\"leaky_relu\")  # 64\n",
        "    self.down2 = gen_block(channels*2, channels*4, contracting_path=True, activation=\"leaky_relu\")  # 32\n",
        "    self.down3 = gen_block(channels*4, channels*8, contracting_path=True, activation=\"leaky_relu\")  # 16\n",
        "    self.down4 = gen_block(channels*8, channels*8, contracting_path=True, activation=\"leaky_relu\")  # 8\n",
        "    self.down5 = gen_block(channels*8, channels*8, contracting_path=True, activation=\"leaky_relu\")  # 4\n",
        "    self.down6 = gen_block(channels*8, channels*8, contracting_path=True, activation=\"leaky_relu\")  # 2\n",
        "\n",
        "    self.bottle_neck = nn.Sequential(\n",
        "        nn.Conv2d(channels*8, channels*8, kernel_size=4, stride=2, padding=1, padding_mode=\"reflect\"),\n",
        "        nn.ReLU()\n",
        "    ) # 1*1\n",
        "\n",
        "    self.up1 = gen_block(channels*8, channels*8, contracting_path=False, activation=\"relu\", use_dropout=True)\n",
        "    self.up2 = gen_block(channels*8*2, channels*8, contracting_path=False, activation=\"relu\", use_dropout=True)\n",
        "    self.up3 = gen_block(channels*8*2, channels*8, contracting_path=False, activation=\"relu\", use_dropout=True)\n",
        "    self.up4 = gen_block(channels*8*2, channels*8, contracting_path=False, activation=\"relu\", use_dropout=False)\n",
        "    self.up5 = gen_block(channels*8*2, channels*4, contracting_path=False, activation=\"relu\", use_dropout=False)\n",
        "    self.up6 = gen_block(channels*4*2, channels*2, contracting_path=False, activation=\"relu\", use_dropout=False)\n",
        "    self.up7 = gen_block(channels*2*2, channels, contracting_path=False, activation=\"relu\", use_dropout=False)\n",
        "    \n",
        "    self.final_block = nn.Sequential(\n",
        "        nn.ConvTranspose2d(channels*2, in_channels, kernel_size=4, stride=2, padding=1),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    d1 = self.initial_block(x)\n",
        "    d2 = self.down1(d1)\n",
        "    d3 = self.down2(d2)\n",
        "    d4 = self.down3(d3)\n",
        "    d5 = self.down4(d4)\n",
        "    d6 = self.down5(d5)\n",
        "    d7 = self.down6(d6)\n",
        "\n",
        "    bottleneck = self.bottle_neck(d7)\n",
        "\n",
        "    u1 = self.up1(bottleneck)\n",
        "    u2 = self.up2(torch.cat([u1, d7], dim=1))\n",
        "    u3 = self.up3(torch.cat([u2, d6], dim=1))\n",
        "    u4 = self.up4(torch.cat([u3, d5], dim=1))\n",
        "    u5 = self.up5(torch.cat([u4, d4], dim=1))\n",
        "    u6 = self.up6(torch.cat([u5, d3], dim=1))\n",
        "    u7 = self.up7(torch.cat([u6, d2], dim=1))\n",
        "\n",
        "    return self.final_block(torch.cat([u7, d1], dim=1))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H2ZzLPIFX6k"
      },
      "source": [
        "### Unit Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLnC_OE5FZKE"
      },
      "source": [
        "def test_generator():\n",
        "  x = torch.randn((1, 3, 256, 256))\n",
        "  model = generator(in_channels=3, channels=64)\n",
        "  preds = model(x)\n",
        "  print(preds.shape)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gon_NDXmF4fP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a5f9ba8-d441-4522-9c37-a5182e0f53a5"
      },
      "source": [
        "test_generator()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 256, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GLblwDzQ95C"
      },
      "source": [
        "### Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6o6yUTaRcr3"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.utils import save_image\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OilS2zNAn--1"
      },
      "source": [
        "!pip install albumentations==0.4.6\n",
        "import albumentations \n",
        "from albumentations.pytorch import ToTensorV2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBvSDzttPjeh",
        "outputId": "7094d020-c14f-4e2b-d5a4-ff369aa563d4"
      },
      "source": [
        "!gdown --id 19BErvkVNU02jPVlbPtjlfNkm_dg7Y7-t"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19BErvkVNU02jPVlbPtjlfNkm_dg7Y7-t\n",
            "To: /content/noaugmentation_512_384_dunet.zip\n",
            "126MB [00:01, 98.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP9zfFBeRA0f"
      },
      "source": [
        "!unzip /content/noaugmentation_512_384_dunet.zip\n",
        "!rm /content/noaugmentation_512_384_dunet.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFg_SbiIXSa3",
        "outputId": "8e215355-2401-49ce-a188-1c14a2b19963"
      },
      "source": [
        "image_dir = \"/content/new_data/valid/image/\"\n",
        "mask_dir = \"/content/new_data/valid/mask/\"\n",
        "\n",
        "images = os.listdir(image_dir)\n",
        "masks = os.listdir(mask_dir)\n",
        "print(len(images), len(masks))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "259 259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyhVvbWvXn8U"
      },
      "source": [
        "for img_file in images:\n",
        "  image = Image.open(os.path.join(image_dir, img_file))\n",
        "  image = image.resize((256, 256))\n",
        "  image.save(os.path.join(image_dir, img_file))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWtmf1D_ZIGk"
      },
      "source": [
        "for mask_file in masks:\n",
        "  mask = Image.open(os.path.join(mask_dir, mask_file))\n",
        "  mask = mask.resize((256, 256))\n",
        "  mask.save(os.path.join(mask_dir, mask_file))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x07oNE9QpkPS"
      },
      "source": [
        "both_transform = albumentations.Compose(\n",
        "    [albumentations.Resize(width=256, height=256),], additional_targets={\"image0\": \"image\"},\n",
        ")\n",
        "\n",
        "transform_only_input = albumentations.Compose(\n",
        "    [\n",
        "        albumentations.HorizontalFlip(p=0.5),\n",
        "        # albumentations.ColorJitter(p=0.2),\n",
        "        albumentations.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0,),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "transform_only_mask = albumentations.Compose(\n",
        "    [\n",
        "        albumentations.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0,),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAE_GxEyRUTi"
      },
      "source": [
        "class map_dataset(Dataset):\n",
        "  def __init__(self, root_dir):\n",
        "    self.root_dir = root_dir\n",
        "    self.image_list = os.listdir(os.path.join(self.root_dir, \"image/\"))\n",
        "    self.mask_list = os.listdir(os.path.join(self.root_dir, \"mask/\"))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_list)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image_file = self.image_list[index]\n",
        "    mask_file = self.mask_list[index]\n",
        "    img_path = os.path.join(self.root_dir, \"image/\")\n",
        "    image_path = os.path.join(img_path, image_file)\n",
        "    msk_path = os.path.join(self.root_dir, \"mask/\")\n",
        "    mask_path = os.path.join(msk_path, mask_file)\n",
        "    input_image = np.array(Image.open(image_path))\n",
        "    target_image = np.array(Image.open(mask_path))\n",
        "\n",
        "    augmentations = both_transform(image=input_image, image0=target_image)\n",
        "    input_image = augmentations[\"image\"]\n",
        "    target_image = augmentations[\"image0\"]\n",
        "\n",
        "    input_image = transform_only_input(image=input_image)[\"image\"]\n",
        "    target_image = transform_only_mask(image=target_image)[\"image\"]\n",
        "\n",
        "    return input_image, target_image"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmhhtmFihOq4"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7oACqaedKl1"
      },
      "source": [
        "def save_some_examples(gen, val_loader, epoch, folder):\n",
        "    x, y = next(iter(val_loader))\n",
        "    x, y = x.to(config.DEVICE), y.to(config.DEVICE)\n",
        "    gen.eval()\n",
        "    with torch.no_grad():\n",
        "        y_fake = gen(x)\n",
        "        y_fake = y_fake * 0.5 + 0.5  # remove normalization#\n",
        "        save_image(y_fake, folder + f\"/y_gen_{epoch}.png\")\n",
        "        save_image(x * 0.5 + 0.5, folder + f\"/input_{epoch}.png\")\n",
        "        if epoch == 1:\n",
        "            save_image(y * 0.5 + 0.5, folder + f\"/label_{epoch}.png\")\n",
        "    gen.train()\n",
        "\n",
        "\n",
        "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=config.DEVICE)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    # If we don't do this then it will just have learning rate of old checkpoint\n",
        "    # and it will lead to many hours of debugging \\:\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_aSD3SuiX8Q"
      },
      "source": [
        "### Configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmWE_UTIiZSa"
      },
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "TRAIN_DIR = \"/content/new_data/valid/\"\n",
        "VAL_DIR = \"/content/new_data/test/\"\n",
        "LEARNING_RATE = 2e-4\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_SIZE = 256\n",
        "CHANNELS_IMG = 3\n",
        "L1_LAMBDA = 100\n",
        "LAMBDA_GP = 10\n",
        "NUM_EPOCHS = 50\n",
        "LOAD_MODEL = False\n",
        "SAVE_MODEL = False\n",
        "CHECKPOINT_DISC = \"disc.pth.tar\"\n",
        "CHECKPOINT_GEN = \"gen.pth.tar\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZoqIdfRhqiO"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50J_PLZjhpxO"
      },
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def train_fn(\n",
        "    disc, gen, loader, opt_disc, opt_gen, l1_loss, bce, g_scaler, d_scaler,\n",
        "):\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "    for idx, (x, y) in enumerate(loop):\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "\n",
        "        # Train Discriminator\n",
        "        with torch.cuda.amp.autocast():\n",
        "            y_fake = gen(x)\n",
        "            D_real = disc(x, y)\n",
        "            D_real_loss = bce(D_real, torch.ones_like(D_real))\n",
        "            D_fake = disc(x, y_fake.detach())\n",
        "            D_fake_loss = bce(D_fake, torch.zeros_like(D_fake))\n",
        "            D_loss = (D_real_loss + D_fake_loss) / 2\n",
        "\n",
        "        disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        # Train generator\n",
        "        with torch.cuda.amp.autocast():\n",
        "            D_fake = disc(x, y_fake)\n",
        "            G_fake_loss = bce(D_fake, torch.ones_like(D_fake))\n",
        "            L1 = l1_loss(y_fake, y) * L1_LAMBDA\n",
        "            G_loss = G_fake_loss + L1\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        if idx % 10 == 0:\n",
        "            loop.set_postfix(\n",
        "                D_real=torch.sigmoid(D_real).mean().item(),\n",
        "                D_fake=torch.sigmoid(D_fake).mean().item(),\n",
        "            )\n",
        "\n",
        "\n",
        "def main():\n",
        "    disc = discriminator(in_channels=3).to(DEVICE)\n",
        "    gen = generator(in_channels=3, channels=64).to(DEVICE)\n",
        "    opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999),)\n",
        "    opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
        "    BCE = nn.BCEWithLogitsLoss()\n",
        "    L1_LOSS = nn.L1Loss()\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN, gen, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_DISC, disc, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "    train_dataset = map_dataset(root_dir=TRAIN_DIR)\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "    )\n",
        "    g_scaler = torch.cuda.amp.GradScaler()\n",
        "    d_scaler = torch.cuda.amp.GradScaler()\n",
        "    val_dataset = map_dataset(root_dir=VAL_DIR)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_fn(\n",
        "            disc, gen, train_loader, opt_disc, opt_gen, L1_LOSS, BCE, g_scaler, d_scaler,\n",
        "        )\n",
        "\n",
        "        if SAVE_MODEL and epoch % 5 == 0:\n",
        "            save_checkpoint(gen, opt_gen, filename=CHECKPOINT_GEN)\n",
        "            save_checkpoint(disc, opt_disc, filename=CHECKPOINT_DISC)\n",
        "\n",
        "        save_some_examples(gen, val_loader, epoch, folder=\"evaluation\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjrkClc2jg5F",
        "outputId": "1f8c858a-8f31-44f3-863d-36b519723ed1"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/autocast_mode.py:120: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n",
            " 18%|█▊        | 3/17 [01:34<07:15, 31.13s/it, D_fake=0.506, D_real=0.495]"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}